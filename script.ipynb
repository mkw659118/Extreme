{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a60cc1a85c1e81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:53:51.382561Z",
     "start_time": "2025-05-30T10:53:51.379687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92366f7f25602f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# 数据库配置\n",
    "import pickle\n",
    "with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "    DB_URI = pickle.load(f)\n",
    "\n",
    "engine = create_engine(DB_URI)\n",
    "DATA_JSON_PATH = './datasets/data.json'\n",
    "\n",
    "# 加载分类数据\n",
    "with open(DATA_JSON_PATH) as f:\n",
    "    group_map = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297cfd7b575be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_idx, (group_name, group_list) in enumerate(group_map.items()):\n",
    "    for group_data in group_list:\n",
    "        if group_name == 'stock1' and group_data['industry_code'] in ['270000', '480000']:\n",
    "            print(group_name, group_data, )\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98e87ed81517e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54aded75946392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(len(group_map['stock1'])):\n",
    "    if group_map['stock1'][i]['industry_code'] == '270000':\n",
    "        print(group_map['stock1'][i])\n",
    "        df['stock-270000'] = group_map['stock1'][i]['code_list']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8455abe8d9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./datasets/benchmark.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7270e2703916f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./datasets/benchmark.pkl', 'rb') as f:\n",
    "    group = pickle.load(f)\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addccdcb5f928a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_value = 'accnav'\n",
    "sql = text(f\"SELECT fund_code, date, nav, accnav, adj_nav FROM b_fund_nav_details_new WHERE fund_code IN :codes AND date BETWEEN :start AND :end ORDER BY date\")\n",
    "df = pd.read_sql_query(\n",
    "    sql.bindparams(codes=tuple(['013152']), start='2020-07-13', end='2025-03-8'),\n",
    "    engine\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80d074f8b5598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stamp = pd.to_datetime(df['date'])\n",
    "df_stamp[1].year, df_stamp[1].month, df_stamp[1].day, df_stamp[1].weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10b8f8729aad3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948aba962b9938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./datasets/lottery/pl3_desc.xls', header=1)\n",
    "timestamps = pd.to_datetime(df['开奖日期'])\n",
    "timestamps = np.array([[ts.year, ts.month, ts.day, ts.weekday()] for ts in timestamps])\n",
    "x = np.array(df['号']).reshape(-1, 1)\n",
    "# timestamps\n",
    "x = np.concatenate((timestamps, x), axis=-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1c64c2b9d5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a7f113fc2a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pretrain_timer import Timer\n",
    "import torch\n",
    "from utils.exp_config import get_config\n",
    "config = get_config()\n",
    "config.patch_len = 96\n",
    "config.d_model = 1024\n",
    "config.d_ff = 2048\n",
    "config.e_layers = 8\n",
    "config.n_heads = 8\n",
    "config.dropout = 0.10\n",
    "config.factor = 1\n",
    "config.output_attention = 1\n",
    "config.activation = 'gelu'\n",
    "config.ckpt_path = 'Timer_forecast_1.0.ckpt'\n",
    "backbone = Timer(config)\n",
    "ckpt_path = 'Timer_forecast_1.0.ckpt'\n",
    "sd = torch.load(ckpt_path, weights_only=False, map_location=\"cpu\")[\"state_dict\"]\n",
    "sd = {k[6:]: v for k, v in sd.items()}\n",
    "backbone.load_state_dict(sd, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c57e88a02587ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:14:22.195421477Z",
     "start_time": "2025-05-14T05:39:11.932833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;2;151;200;129m|2025-05-14 13:39:14| \u001b[0m\u001b[1m{\n",
      "     'ablation': 0, 'att_method': self, 'bs': 32\n",
      "     'classification': False, 'continue_train': False, 'dataset': financial\n",
      "     'debug': False, 'decay': 0.0001, 'density': 0.7\n",
      "     'device': cuda, 'dis_method': cosine, 'epochs': 200\n",
      "     'eval_set': True, 'ffn_method': moe, 'fft': False\n",
      "     'hyper_search': False, 'idx': 0, 'log': <utils.exp_logger.Logger object at 0x738009311f70>\n",
      "     'logger': None, 'loss_func': MSELoss, 'lr': 0.001\n",
      "     'model': ours, 'monitor_metric': MAE, 'multi_dataset': True\n",
      "     'norm_method': rms, 'num_layers': 4, 'optim': AdamW\n",
      "     'path': ./datasets/, 'patience': 30, 'pred_len': 10\n",
      "     'rank': 64, 'record': True, 'retrain': True\n",
      "     'revin': False, 'rounds': 1, 'scaler_method': stander\n",
      "     'seed': 0, 'seq_len': 48, 'shuffle': False\n",
      "     'train_size': 500, 'try_exp': 1, 'ts_var': 0\n",
      "     'use_train_size': False, 'verbose': 5\n",
      "}\u001b[0m\n",
      "./datasets/financial/560100.pkl\n",
      "(761, 8) (761,)\n",
      "./datasets/financial/560100.pkl\n",
      "(761, 8) (761,)\n",
      "./datasets/financial/015593.pkl\n",
      "(697, 8) (697,)\n",
      "./datasets/financial/012320.pkl\n",
      "(830, 8) (830,)\n",
      "./datasets/financial/012319.pkl\n",
      "(830, 8) (830,)\n",
      "./datasets/financial/013339.pkl\n",
      "(840, 8) (840,)\n",
      "./datasets/financial/013340.pkl\n",
      "(840, 8) (840,)\n",
      "./datasets/financial/014418.pkl\n",
      "(787, 8) (787,)\n",
      "./datasets/financial/014419.pkl\n",
      "(787, 8) (787,)\n",
      "./datasets/financial/016052.pkl\n",
      "(659, 8) (659,)\n",
      "./datasets/financial/014193.pkl\n",
      "(799, 8) (799,)\n",
      "./datasets/financial/014194.pkl\n",
      "(799, 8) (799,)\n",
      "./datasets/financial/014587.pkl\n",
      "(684, 8) (684,)\n",
      "./datasets/financial/014588.pkl\n",
      "(684, 8) (684,)\n",
      "./datasets/financial/015773.pkl\n",
      "(697, 8) (697,)\n",
      "./datasets/financial/013242.pkl\n",
      "(839, 8) (839,)\n",
      "./datasets/financial/014854.pkl\n",
      "(701, 8) (701,)\n",
      "./datasets/financial/014855.pkl\n",
      "(701, 8) (701,)\n",
      "./datasets/financial/013465.pkl\n",
      "(778, 8) (778,)\n",
      "./datasets/financial/013466.pkl\n",
      "(778, 8) (778,)\n",
      "./datasets/financial/013005.pkl\n",
      "(817, 8) (817,)\n",
      "./datasets/financial/013004.pkl\n",
      "(817, 8) (817,)\n",
      "./datasets/financial/015075.pkl\n",
      "(756, 8) (756,)\n",
      "./datasets/financial/013622.pkl\n",
      "(838, 8) (838,)\n",
      "./datasets/financial/014299.pkl\n",
      "(732, 8) (732,)\n",
      "./datasets/financial/014300.pkl\n",
      "(732, 8) (732,)\n",
      "./datasets/financial/015199.pkl\n",
      "(742, 8) (742,)\n",
      "./datasets/financial/015198.pkl\n",
      "(742, 8) (742,)\n",
      "./datasets/financial/014377.pkl\n",
      "(724, 8) (724,)\n",
      "./datasets/financial/014376.pkl\n",
      "(724, 8) (724,)\n",
      "./datasets/financial/012496.pkl\n",
      "(822, 8) (822,)\n",
      "./datasets/financial/012497.pkl\n",
      "(822, 8) (822,)\n",
      "./datasets/financial/012696.pkl\n",
      "(848, 8) (848,)\n",
      "./datasets/financial/012697.pkl\n",
      "(848, 8) (848,)\n",
      "(17801, 8) (17801,)\n",
      "\u001b[1;38;2;151;200;129m|2025-05-14 13:39:14| \u001b[0m\u001b[1mTrain_length : 17744 Valid_length : 2473 Test_length : 5067\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rtx4090/code/python/TimeSeries/modules/load_data/get_financial.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  all_train_x[:, -i] = (all_train_x[:, -i] - now_mean) / now_std\n",
      "/home/rtx4090/code/python/TimeSeries/modules/load_data/get_financial.py:134: RuntimeWarning: invalid value encountered in divide\n",
      "  all_valid_x[:, -i] = (all_valid_x[:, -i] - now_mean) / now_std\n",
      "/home/rtx4090/code/python/TimeSeries/modules/load_data/get_financial.py:135: RuntimeWarning: invalid value encountered in divide\n",
      "  all_test_x[:, -i] = (all_test_x[:, -i] - now_mean) / now_std\n"
     ]
    }
   ],
   "source": [
    "from utils.exp_logger import Logger\n",
    "from utils.exp_metrics_plotter import MetricsPlotter\n",
    "from run_train import get_experiment_name\n",
    "from utils.utils import set_settings\n",
    "from a_data_center import DataModule\n",
    "# Experiment Settings, logger, plotter\n",
    "from utils.exp_config import get_config\n",
    "config = get_config()\n",
    "config.multi_dataset = True\n",
    "set_settings(config)\n",
    "log_filename, exper_detail = get_experiment_name(config)\n",
    "plotter = MetricsPlotter(log_filename, config)\n",
    "log = Logger(log_filename, exper_detail, plotter, config)\n",
    "datamodule = DataModule(config)\n",
    "# model = Model(datamodule, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83d067d4d4b3419b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:39:54.525191Z",
     "start_time": "2025-05-14T07:39:54.497395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 48, 33, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设输入\n",
    "bs, seq_len, channels, dim = 16, 48, 33, 64\n",
    "x_enc = torch.randn(bs, seq_len, channels, dim)\n",
    "\n",
    "# 定义 attention 层（无 batch_first 参数）\n",
    "attn_channel = nn.MultiheadAttention(embed_dim=dim, num_heads=8)  # expects (seq_len, batch, dim)\n",
    "attn_time = nn.MultiheadAttention(embed_dim=dim, num_heads=8)\n",
    "\n",
    "# ===== 1. 跨通道 attention =====\n",
    "# 原始 x_enc: (bs, 48, 33, 64)\n",
    "# 调整为 (33, bs*48, 64)\n",
    "x_enc_reshaped = x_enc.permute(2, 0, 1, 3).reshape(channels, bs * seq_len, dim)\n",
    "\n",
    "# 注意力：通道之间的 self-attention\n",
    "x_channel_attn, _ = attn_channel(x_enc_reshaped, x_enc_reshaped, x_enc_reshaped)  # (33, bs*48, 64)\n",
    "\n",
    "# 还原为 (bs, 48, 33, 64)\n",
    "x_channel_attn = x_channel_attn.reshape(channels, bs, seq_len, dim).permute(1, 2, 0, 3)\n",
    "\n",
    "# ===== 2. 跨时间 attention =====\n",
    "# 调整为 (48, bs*33, 64)\n",
    "x_time_input = x_channel_attn.permute(1, 0, 2, 3).reshape(seq_len, bs * channels, dim)\n",
    "\n",
    "# 注意力：时间步之间的 self-attention\n",
    "x_time_attn, _ = attn_time(x_time_input, x_time_input, x_time_input)  # (48, bs*33, 64)\n",
    "\n",
    "# 还原为 (bs, 48, 33, 64)\n",
    "x_time_attn = x_time_attn.reshape(seq_len, bs, channels, dim).permute(1, 0, 2, 3)\n",
    "\n",
    "# 最终输出\n",
    "print(x_time_attn.shape)  # torch.Size([16, 48, 33, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34b77a8a50c3e4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:54:42.394091Z",
     "start_time": "2025-05-15T08:54:42.206443Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.backbone import Backbone\n",
    "from run_train import *\n",
    "\n",
    "from utils.exp_config import get_config\n",
    "config = get_config()\n",
    "# datamodule = DataModule(config)\n",
    "# model = Model(datamodule, config)\n",
    "model = Backbone(3, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0cc9844e24299a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:54:44.753971Z",
     "start_time": "2025-05-15T08:54:44.746305Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 33, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1df9f4965779f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:55:06.532773Z",
     "start_time": "2025-05-15T08:55:06.526640Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 1, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb1fd89c0e320dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:27:41.716108Z",
     "start_time": "2025-05-15T07:27:41.708539Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 16, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f80826f96e2ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>...</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>raining (s)</th>\n",
       "      <th>SWDR (W/m�)</th>\n",
       "      <th>PAR (�mol/m�/s)</th>\n",
       "      <th>max. PAR (�mol/m�/s)</th>\n",
       "      <th>Tlog (degC)</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:10:00</td>\n",
       "      <td>1008.89</td>\n",
       "      <td>0.71</td>\n",
       "      <td>273.18</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>86.1</td>\n",
       "      <td>6.43</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.42</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.60</td>\n",
       "      <td>224.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.45</td>\n",
       "      <td>428.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:20:00</td>\n",
       "      <td>1008.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>273.22</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>85.2</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>206.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.51</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:30:00</td>\n",
       "      <td>1008.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>273.21</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>85.1</td>\n",
       "      <td>6.44</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.48</td>\n",
       "      <td>197.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>427.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:40:00</td>\n",
       "      <td>1008.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>272.86</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>86.3</td>\n",
       "      <td>6.27</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>206.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:50:00</td>\n",
       "      <td>1008.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>272.82</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>87.4</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.40</td>\n",
       "      <td>209.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.81</td>\n",
       "      <td>432.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52691</th>\n",
       "      <td>2020-12-31 23:20:00</td>\n",
       "      <td>978.32</td>\n",
       "      <td>2.28</td>\n",
       "      <td>277.16</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.40</td>\n",
       "      <td>180.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.40</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52692</th>\n",
       "      <td>2020-12-31 23:30:00</td>\n",
       "      <td>978.30</td>\n",
       "      <td>2.13</td>\n",
       "      <td>277.01</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>83.1</td>\n",
       "      <td>7.12</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.42</td>\n",
       "      <td>439.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52693</th>\n",
       "      <td>2020-12-31 23:40:00</td>\n",
       "      <td>978.26</td>\n",
       "      <td>1.99</td>\n",
       "      <td>276.88</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>82.2</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1.26</td>\n",
       "      <td>3.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>248.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.45</td>\n",
       "      <td>435.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52694</th>\n",
       "      <td>2020-12-31 23:50:00</td>\n",
       "      <td>978.26</td>\n",
       "      <td>2.07</td>\n",
       "      <td>276.95</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>81.4</td>\n",
       "      <td>7.09</td>\n",
       "      <td>5.77</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.07</td>\n",
       "      <td>196.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.47</td>\n",
       "      <td>433.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52695</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>978.24</td>\n",
       "      <td>2.01</td>\n",
       "      <td>276.89</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>82.4</td>\n",
       "      <td>7.06</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.08</td>\n",
       "      <td>221.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.48</td>\n",
       "      <td>436.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52696 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0      2020-01-01 00:10:00   1008.89      0.71    273.18        -1.33    86.1   \n",
       "1      2020-01-01 00:20:00   1008.76      0.75    273.22        -1.44    85.2   \n",
       "2      2020-01-01 00:30:00   1008.66      0.73    273.21        -1.48    85.1   \n",
       "3      2020-01-01 00:40:00   1008.64      0.37    272.86        -1.64    86.3   \n",
       "4      2020-01-01 00:50:00   1008.61      0.33    272.82        -1.50    87.4   \n",
       "...                    ...       ...       ...       ...          ...     ...   \n",
       "52691  2020-12-31 23:20:00    978.32      2.28    277.16        -0.80    80.0   \n",
       "52692  2020-12-31 23:30:00    978.30      2.13    277.01        -0.43    83.1   \n",
       "52693  2020-12-31 23:40:00    978.26      1.99    276.88        -0.71    82.2   \n",
       "52694  2020-12-31 23:50:00    978.26      2.07    276.95        -0.77    81.4   \n",
       "52695  2021-01-01 00:00:00    978.24      2.01    276.89        -0.66    82.4   \n",
       "\n",
       "       VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  ...  wv (m/s)  \\\n",
       "0              6.43          5.54          0.89       3.42  ...      1.02   \n",
       "1              6.45          5.49          0.95       3.39  ...      0.43   \n",
       "2              6.44          5.48          0.96       3.39  ...      0.61   \n",
       "3              6.27          5.41          0.86       3.35  ...      1.11   \n",
       "4              6.26          5.47          0.79       3.38  ...      0.49   \n",
       "...             ...           ...           ...        ...  ...       ...   \n",
       "52691          7.20          5.76          1.44       3.67  ...      0.73   \n",
       "52692          7.12          5.92          1.20       3.77  ...      0.43   \n",
       "52693          7.05          5.80          1.26       3.69  ...      0.38   \n",
       "52694          7.09          5.77          1.32       3.68  ...      0.57   \n",
       "52695          7.06          5.82          1.24       3.71  ...      0.57   \n",
       "\n",
       "       max. wv (m/s)  wd (deg)  rain (mm)  raining (s)  SWDR (W/m�)  \\\n",
       "0               1.60     224.3        0.0          0.0          0.0   \n",
       "1               0.84     206.8        0.0          0.0          0.0   \n",
       "2               1.48     197.1        0.0          0.0          0.0   \n",
       "3               1.48     206.4        0.0          0.0          0.0   \n",
       "4               1.40     209.6        0.0          0.0          0.0   \n",
       "...              ...       ...        ...          ...          ...   \n",
       "52691           1.40     180.6        0.0          0.0          0.0   \n",
       "52692           0.82     174.0        0.0          0.0          0.0   \n",
       "52693           0.76     248.9        0.0          0.0          0.0   \n",
       "52694           1.07     196.6        0.0          0.0          0.0   \n",
       "52695           1.08     221.3        0.0          0.0          0.0   \n",
       "\n",
       "       PAR (�mol/m�/s)  max. PAR (�mol/m�/s)  Tlog (degC)     OT  \n",
       "0                  0.0                   0.0        11.45  428.1  \n",
       "1                  0.0                   0.0        11.51  428.0  \n",
       "2                  0.0                   0.0        11.60  427.6  \n",
       "3                  0.0                   0.0        11.70  430.0  \n",
       "4                  0.0                   0.0        11.81  432.2  \n",
       "...                ...                   ...          ...    ...  \n",
       "52691              0.0                   0.0        13.40  433.0  \n",
       "52692              0.0                   0.0        13.42  439.6  \n",
       "52693              0.0                   0.0        13.45  435.2  \n",
       "52694              0.0                   0.0        13.47  433.9  \n",
       "52695              0.0                   0.0        13.48  436.5  \n",
       "\n",
       "[52696 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('datasets/weather/weather.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71b0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "def insert_pred_to_sql():\n",
    "    # 读取数据库连接字符串\n",
    "    with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "        DB_URI = pickle.load(f)\n",
    "\n",
    "    # 创建数据库引擎\n",
    "    engine = create_engine(DB_URI)\n",
    "\n",
    "    # SQL 查询语句\n",
    "    sql = text(\"\"\"\n",
    "        SELECT fund_code, forecast_date, pre_data, model_version, create_time, update_time\n",
    "        FROM b_fund_forecast_new\n",
    "        WHERE fund_code IN :codes\n",
    "        ORDER BY forecast_date\n",
    "    \"\"\")\n",
    "\n",
    "    # 执行查询，传入参数（注意 tuple 中只有一个元素时加逗号）\n",
    "    df = pd.read_sql_query(\n",
    "        sql.bindparams(codes=tuple(['005626'])),  # 或 codes=('005626',)\n",
    "        engine\n",
    "    )\n",
    "    \n",
    "    df.to_sql('my_table', engine, if_exists='replace', index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9126f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# for i in range(len(df)):\n",
    "#     pred_str = df['pre_data'][i]\n",
    "#     str_start = pred_str.find('[') + 1\n",
    "#     str_end = pred_str.find(']') \n",
    "#     pred = pred_str[str_start:str_end].split(', ')\n",
    "#     pred = np.array(pred, dtype=np.float32)\n",
    "#     # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f9f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_start_date(end_date: str, window_size: int) -> str:\n",
    "    \"\"\"\n",
    "    给定结束日期和历史窗口长度，返回窗口开始日期（字符串格式）。\n",
    "\n",
    "    参数：\n",
    "    - end_date (str): 结束日期，格式 'YYYY-MM-DD'\n",
    "    - window_size (int): 历史窗口长度（天数）\n",
    "\n",
    "    返回：\n",
    "    - start_date (str): 开始日期，格式 'YYYY-MM-DD'\n",
    "    \"\"\"\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    start_dt = end_dt - timedelta(days=window_size)\n",
    "    return start_dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5123636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.generate_financial import process_date_columns, query_fund_data\n",
    "from data_provider.get_financial import get_group_idx\n",
    "from utils.exp_config import get_config\n",
    "import pickle \n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "\n",
    "config = get_config('FinancialConfig')\n",
    "\n",
    "# 读取数据库连接字符串\n",
    "with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "    DB_URI = pickle.load(f)\n",
    "\n",
    "# 创建数据库引擎\n",
    "engine = create_engine(DB_URI)\n",
    "now_fund_code = get_group_idx(27)\n",
    "end_date = '2025-4-15'\n",
    "all_history_input = []\n",
    "for i in range(len(now_fund_code)):\n",
    "    start_date = get_start_date(end_date, window_size=64)\n",
    "    df = query_fund_data(now_fund_code[i], start_date, end_date)\n",
    "    df = process_date_columns(df)\n",
    "    all_history_input.append(df)\n",
    "\n",
    "df = all_history_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237ab5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d32fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基金 008783 缺失日期：['2025-04-04']\n",
      "基金 519945 缺失日期：['2025-04-04']\n",
      "基金 007097 缺失日期：['2025-04-04']\n",
      "基金 002994 缺失日期：['2025-04-04']\n",
      "基金 011048 缺失日期：['2025-04-04']\n",
      "基金 001423 缺失日期：['2025-04-04']\n",
      "基金 007561 缺失日期：['2025-04-04']\n",
      "基金 006468 缺失日期：['2025-04-04']\n",
      "基金 519777 缺失日期：['2025-04-04']\n",
      "基金 007116 缺失日期：['2025-04-04']\n",
      "基金 217003 缺失日期：['2025-04-04']\n",
      "基金 002915 缺失日期：['2025-04-04']\n",
      "基金 007954 缺失日期：['2025-04-04']\n",
      "基金 002364 缺失日期：['2025-04-04']\n",
      "基金 008582 缺失日期：['2025-04-04']\n",
      "基金 012750 缺失日期：['2025-04-04']\n",
      "基金 002363 缺失日期：['2025-04-04']\n",
      "基金 002966 缺失日期：['2025-04-04']\n",
      "基金 006077 缺失日期：['2025-04-04']\n",
      "基金 005363 缺失日期：['2025-04-04']\n",
      "基金 011049 缺失日期：['2025-04-04']\n",
      "基金 007259 缺失日期：['2025-04-04']\n",
      "基金 003330 缺失日期：['2025-04-04']\n",
      "基金 006076 缺失日期：['2025-04-04']\n",
      "基金 006897 缺失日期：['2025-04-04']\n",
      "基金 003329 缺失日期：['2025-04-04']\n",
      "基金 003619 缺失日期：['2025-04-04']\n",
      "基金 003041 缺失日期：['2025-04-04']\n",
      "基金 011094 缺失日期：['2025-04-04']\n",
      "基金 012625 缺失日期：['2025-04-04']\n",
      "基金 007768 缺失日期：['2025-04-04']\n",
      "基金 003618 缺失日期：['2025-04-04']\n",
      "基金 005431 缺失日期：['2025-04-04']\n",
      "基金 000199 缺失日期：['2025-04-04']\n",
      "基金 002268 缺失日期：['2025-04-04']\n",
      "基金 008652 缺失日期：['2025-04-04']\n",
      "基金 003209 缺失日期：['2025-04-04']\n",
      "基金 012624 缺失日期：['2025-04-04']\n",
      "基金 005302 缺失日期：['2025-04-04']\n",
      "基金 512390 缺失日期：['2025-04-04']\n",
      "基金 013716 缺失日期：['2025-04-04']\n",
      "基金 006978 缺失日期：['2025-04-04']\n",
      "基金 001422 缺失日期：['2025-04-04']\n",
      "基金 003210 缺失日期：['2025-04-04']\n",
      "基金 007560 缺失日期：['2025-04-04']\n",
      "基金 008653 缺失日期：['2025-04-04']\n",
      "基金 519519 缺失日期：['2025-04-04']\n",
      "基金 008081 缺失日期：['2025-04-04']\n",
      "基金 164703 缺失日期：['2025-04-04']\n",
      "基金 005201 缺失日期：['2025-04-04']\n",
      "基金 005301 缺失日期：['2025-04-04']\n",
      "基金 005362 缺失日期：['2025-04-04']\n",
      "基金 519944 缺失日期：['2025-04-04']\n",
      "基金 004108 缺失日期：['2025-04-04']\n",
      "基金 006210 缺失日期：['2025-04-04']\n",
      "基金 010767 缺失日期：['2025-04-04']\n",
      "基金 007870 缺失日期：['2025-04-04']\n",
      "基金 007098 缺失日期：['2025-04-04']\n",
      "基金 000016 缺失日期：['2025-04-04']\n",
      "基金 003123 缺失日期：['2025-04-04']\n",
      "基金 013717 缺失日期：['2025-04-04']\n",
      "基金 005200 缺失日期：['2025-04-04']\n",
      "基金 006979 缺失日期：['2025-04-04']\n",
      "基金 310508 缺失日期：['2025-04-04']\n",
      "基金 013391 缺失日期：['2025-04-04']\n",
      "基金 004168 缺失日期：['2025-04-04']\n",
      "基金 004059 缺失日期：['2025-04-04']\n",
      "基金 350005 缺失日期：['2025-04-04']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_array_to_df(array):\n",
    "    \"\"\"\n",
    "    将数组转换为包含标准日期列的 DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(array, columns=[\n",
    "        'fund_code', 'year', 'month', 'day', 'weekday',\n",
    "        'value1', 'value2', 'value3'\n",
    "    ])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    df['month'] = df['month'].astype(int)\n",
    "    df['day'] = df['day'].astype(int)\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    return df\n",
    "\n",
    "def find_missing_dates_from_array_list(array_list, start_date, end_date, freq='B'):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - array_list: List[np.ndarray]，每个元素是一个基金的历史数据数组\n",
    "    - start_date, end_date: 'YYYY-MM-DD'\n",
    "    - freq: 'B' 表示工作日（默认）\n",
    "\n",
    "    返回：\n",
    "    - dict: {fund_code: [缺失的日期列表]}\n",
    "    \"\"\"\n",
    "    full_range = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "    missing_map = {}\n",
    "\n",
    "    for arr in array_list:\n",
    "        df = convert_array_to_df(arr)\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        fund_code = df.iloc[0]['fund_code']\n",
    "        date_series = df['date']\n",
    "        missing = full_range.difference(date_series)\n",
    "\n",
    "        if not missing.empty:\n",
    "            missing_map[fund_code] = missing.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "    return missing_map\n",
    "\n",
    "missing_map = find_missing_dates_from_array_list(df, start_date, end_date)\n",
    "\n",
    "for code, dates in missing_map.items():\n",
    "    print(f\"基金 {code} 缺失日期：{dates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c819d60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 46, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.array(all_history_input)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af832df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 68, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.stack(df, axis=0)\n",
    "data = data.transpose(1, 0, 2)\n",
    "x = data[:, :, :]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c8f9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['008783', 2025, 2, ..., 1.0592, 1.1442, 1.1494],\n",
       "        ['519945', 2025, 2, ..., 1.0868, 1.4769, 1.5765],\n",
       "        ['007097', 2025, 2, ..., 1.0419, 1.1961, 1.212],\n",
       "        ...,\n",
       "        ['004168', 2025, 2, ..., 1.1085, 1.2978, 1.3231],\n",
       "        ['004059', 2025, 2, ..., 1.0254, 1.298, 1.3325],\n",
       "        ['350005', 2025, 2, ..., 2.0466, 2.8033, 2.8425]],\n",
       "\n",
       "       [['008783', 2025, 2, ..., 1.0592, 1.1442, 1.1494],\n",
       "        ['519945', 2025, 2, ..., 1.0867, 1.4768, 1.5763],\n",
       "        ['007097', 2025, 2, ..., 1.042, 1.1962, 1.2121],\n",
       "        ...,\n",
       "        ['004168', 2025, 2, ..., 1.1087, 1.298, 1.3233],\n",
       "        ['004059', 2025, 2, ..., 1.0253, 1.2979, 1.3324],\n",
       "        ['350005', 2025, 2, ..., 2.0482, 2.8049, 2.8447]],\n",
       "\n",
       "       [['008783', 2025, 2, ..., 1.0588, 1.1438, 1.1489],\n",
       "        ['519945', 2025, 2, ..., 1.0867, 1.4768, 1.5763],\n",
       "        ['007097', 2025, 2, ..., 1.0418, 1.196, 1.2119],\n",
       "        ...,\n",
       "        ['004168', 2025, 2, ..., 1.1084, 1.2977, 1.3229],\n",
       "        ['004059', 2025, 2, ..., 1.0252, 1.2978, 1.3322],\n",
       "        ['350005', 2025, 2, ..., 2.0572, 2.8139, 2.8572]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [['008783', 2025, 4, ..., 1.059, 1.144, 1.1491],\n",
       "        ['519945', 2025, 4, ..., 1.092, 1.4821, 1.584],\n",
       "        ['007097', 2025, 4, ..., 1.0411, 1.1953, 1.2111],\n",
       "        ...,\n",
       "        ['004168', 2025, 4, ..., 1.0068, 1.2931, 1.3178],\n",
       "        ['004059', 2025, 4, ..., 1.0252, 1.2978, 1.3322],\n",
       "        ['350005', 2025, 4, ..., 1.8763, 2.633, 2.606]],\n",
       "\n",
       "       [['008783', 2025, 4, ..., 1.059, 1.144, 1.1491],\n",
       "        ['519945', 2025, 4, ..., 1.0922, 1.4823, 1.5843],\n",
       "        ['007097', 2025, 4, ..., 1.041, 1.1952, 1.2109],\n",
       "        ...,\n",
       "        ['004168', 2025, 4, ..., 1.0068, 1.2931, 1.3178],\n",
       "        ['004059', 2025, 4, ..., 1.0253, 1.2979, 1.3324],\n",
       "        ['350005', 2025, 4, ..., 1.8922, 2.6489, 2.6281]],\n",
       "\n",
       "       [['008783', 2025, 4, ..., 1.059, 1.144, 1.1491],\n",
       "        ['519945', 2025, 4, ..., 1.0922, 1.4823, 1.5843],\n",
       "        ['007097', 2025, 4, ..., 1.041, 1.1952, 1.2109],\n",
       "        ...,\n",
       "        ['004168', 2025, 4, ..., 1.0067, 1.293, 1.3176],\n",
       "        ['004059', 2025, 4, ..., 1.0253, 1.2979, 1.3324],\n",
       "        ['350005', 2025, 4, ..., 1.8782, 2.6349, 2.6086]]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2803a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_start_date(end_date: str, window_size: int) -> str:\n",
    "    \"\"\"\n",
    "    给定结束日期和历史窗口长度，返回窗口开始日期（字符串格式）。\n",
    "\n",
    "    参数：\n",
    "    - end_date (str): 结束日期，格式 'YYYY-MM-DD'\n",
    "    - window_size (int): 历史窗口长度（天数）\n",
    "\n",
    "    返回：\n",
    "    - start_date (str): 开始日期，格式 'YYYY-MM-DD'\n",
    "    \"\"\"\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    start_dt = end_dt - timedelta(days=window_size)\n",
    "    return start_dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc60322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from data_provider.generate_financial import process_date_columns, query_fund_data\n",
    "from utils.exp_config import get_config\n",
    "from data_provider.get_financial import get_group_idx\n",
    "import pickle \n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "\n",
    "config = get_config('FinancialConfig')\n",
    "\n",
    "# 读取数据库连接字符串\n",
    "with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "    DB_URI = pickle.load(f)\n",
    "\n",
    "# 创建数据库引擎\n",
    "engine = create_engine(DB_URI)\n",
    "now_fund_code = get_group_idx(27)\n",
    "end_date = '2025-4-15'\n",
    "all_history_input = []\n",
    "for i in range(len(now_fund_code)):\n",
    "    start_date = get_start_date(end_date, window_size=64)\n",
    "    df = query_fund_data(now_fund_code[i], start_date, end_date)\n",
    "    df = process_date_columns(df)\n",
    "    all_history_input.append(df)\n",
    "df = all_history_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a799e87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 68, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.stack(df, axis=0)\n",
    "data = data.transpose(1, 0, 2)\n",
    "x = data[:, :, :]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac517d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192144/804212040.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = Backbone(3, config).load_state_dict(torch.load('checkpoints/ours/Model_ours_Dataset_financial_Multi_round_0.pt'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Backbone:\n\tMissing key(s) in state_dict: \"projection.weight\", \"projection.bias\", \"position_embedding.pos_encoding.embedding.weight\", \"fund_embedding.weight\", \"predict_linear.weight\", \"predict_linear.bias\", \"encoder.layers.0.0.weight\", \"encoder.layers.0.1.att.in_proj_weight\", \"encoder.layers.0.1.att.in_proj_bias\", \"encoder.layers.0.1.att.out_proj.weight\", \"encoder.layers.0.1.att.out_proj.bias\", \"encoder.layers.0.2.weight\", \"encoder.layers.0.3.net.0.weight\", \"encoder.layers.0.3.net.0.bias\", \"encoder.layers.0.3.net.2.weight\", \"encoder.layers.0.3.net.2.bias\", \"encoder.layers.1.0.weight\", \"encoder.layers.1.1.att.in_proj_weight\", \"encoder.layers.1.1.att.in_proj_bias\", \"encoder.layers.1.1.att.out_proj.weight\", \"encoder.layers.1.1.att.out_proj.bias\", \"encoder.layers.1.2.weight\", \"encoder.layers.1.3.net.0.weight\", \"encoder.layers.1.3.net.0.bias\", \"encoder.layers.1.3.net.2.weight\", \"encoder.layers.1.3.net.2.bias\", \"encoder.norm.weight\", \"encoder2.layers.0.0.weight\", \"encoder2.layers.0.1.att.in_proj_weight\", \"encoder2.layers.0.1.att.in_proj_bias\", \"encoder2.layers.0.1.att.out_proj.weight\", \"encoder2.layers.0.1.att.out_proj.bias\", \"encoder2.layers.0.2.weight\", \"encoder2.layers.0.3.net.0.weight\", \"encoder2.layers.0.3.net.0.bias\", \"encoder2.layers.0.3.net.2.weight\", \"encoder2.layers.0.3.net.2.bias\", \"encoder2.layers.1.0.weight\", \"encoder2.layers.1.1.att.in_proj_weight\", \"encoder2.layers.1.1.att.in_proj_bias\", \"encoder2.layers.1.1.att.out_proj.weight\", \"encoder2.layers.1.1.att.out_proj.bias\", \"encoder2.layers.1.2.weight\", \"encoder2.layers.1.3.net.0.weight\", \"encoder2.layers.1.3.net.0.bias\", \"encoder2.layers.1.3.net.2.weight\", \"encoder2.layers.1.3.net.2.bias\", \"encoder2.norm.weight\", \"decoder.weight\", \"decoder.bias\". \n\tUnexpected key(s) in state_dict: \"model.projection.weight\", \"model.projection.bias\", \"model.position_embedding.pos_encoding.embedding.weight\", \"model.fund_embedding.weight\", \"model.predict_linear.weight\", \"model.predict_linear.bias\", \"model.encoder.layers.0.0.weight\", \"model.encoder.layers.0.1.att.in_proj_weight\", \"model.encoder.layers.0.1.att.in_proj_bias\", \"model.encoder.layers.0.1.att.out_proj.weight\", \"model.encoder.layers.0.1.att.out_proj.bias\", \"model.encoder.layers.0.2.weight\", \"model.encoder.layers.0.3.net.0.weight\", \"model.encoder.layers.0.3.net.0.bias\", \"model.encoder.layers.0.3.net.2.weight\", \"model.encoder.layers.0.3.net.2.bias\", \"model.encoder.layers.1.0.weight\", \"model.encoder.layers.1.1.att.in_proj_weight\", \"model.encoder.layers.1.1.att.in_proj_bias\", \"model.encoder.layers.1.1.att.out_proj.weight\", \"model.encoder.layers.1.1.att.out_proj.bias\", \"model.encoder.layers.1.2.weight\", \"model.encoder.layers.1.3.net.0.weight\", \"model.encoder.layers.1.3.net.0.bias\", \"model.encoder.layers.1.3.net.2.weight\", \"model.encoder.layers.1.3.net.2.bias\", \"model.encoder.norm.weight\", \"model.encoder2.layers.0.0.weight\", \"model.encoder2.layers.0.1.att.in_proj_weight\", \"model.encoder2.layers.0.1.att.in_proj_bias\", \"model.encoder2.layers.0.1.att.out_proj.weight\", \"model.encoder2.layers.0.1.att.out_proj.bias\", \"model.encoder2.layers.0.2.weight\", \"model.encoder2.layers.0.3.net.0.weight\", \"model.encoder2.layers.0.3.net.0.bias\", \"model.encoder2.layers.0.3.net.2.weight\", \"model.encoder2.layers.0.3.net.2.bias\", \"model.encoder2.layers.1.0.weight\", \"model.encoder2.layers.1.1.att.in_proj_weight\", \"model.encoder2.layers.1.1.att.in_proj_bias\", \"model.encoder2.layers.1.1.att.out_proj.weight\", \"model.encoder2.layers.1.1.att.out_proj.bias\", \"model.encoder2.layers.1.2.weight\", \"model.encoder2.layers.1.3.net.0.weight\", \"model.encoder2.layers.1.3.net.0.bias\", \"model.encoder2.layers.1.3.net.2.weight\", \"model.encoder2.layers.1.3.net.2.bias\", \"model.encoder2.norm.weight\", \"model.decoder.weight\", \"model.decoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Backbone\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m Backbone(\u001b[38;5;241m3\u001b[39m, config)\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/ours/Model_ours_Dataset_financial_Multi_round_0.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Backbone:\n\tMissing key(s) in state_dict: \"projection.weight\", \"projection.bias\", \"position_embedding.pos_encoding.embedding.weight\", \"fund_embedding.weight\", \"predict_linear.weight\", \"predict_linear.bias\", \"encoder.layers.0.0.weight\", \"encoder.layers.0.1.att.in_proj_weight\", \"encoder.layers.0.1.att.in_proj_bias\", \"encoder.layers.0.1.att.out_proj.weight\", \"encoder.layers.0.1.att.out_proj.bias\", \"encoder.layers.0.2.weight\", \"encoder.layers.0.3.net.0.weight\", \"encoder.layers.0.3.net.0.bias\", \"encoder.layers.0.3.net.2.weight\", \"encoder.layers.0.3.net.2.bias\", \"encoder.layers.1.0.weight\", \"encoder.layers.1.1.att.in_proj_weight\", \"encoder.layers.1.1.att.in_proj_bias\", \"encoder.layers.1.1.att.out_proj.weight\", \"encoder.layers.1.1.att.out_proj.bias\", \"encoder.layers.1.2.weight\", \"encoder.layers.1.3.net.0.weight\", \"encoder.layers.1.3.net.0.bias\", \"encoder.layers.1.3.net.2.weight\", \"encoder.layers.1.3.net.2.bias\", \"encoder.norm.weight\", \"encoder2.layers.0.0.weight\", \"encoder2.layers.0.1.att.in_proj_weight\", \"encoder2.layers.0.1.att.in_proj_bias\", \"encoder2.layers.0.1.att.out_proj.weight\", \"encoder2.layers.0.1.att.out_proj.bias\", \"encoder2.layers.0.2.weight\", \"encoder2.layers.0.3.net.0.weight\", \"encoder2.layers.0.3.net.0.bias\", \"encoder2.layers.0.3.net.2.weight\", \"encoder2.layers.0.3.net.2.bias\", \"encoder2.layers.1.0.weight\", \"encoder2.layers.1.1.att.in_proj_weight\", \"encoder2.layers.1.1.att.in_proj_bias\", \"encoder2.layers.1.1.att.out_proj.weight\", \"encoder2.layers.1.1.att.out_proj.bias\", \"encoder2.layers.1.2.weight\", \"encoder2.layers.1.3.net.0.weight\", \"encoder2.layers.1.3.net.0.bias\", \"encoder2.layers.1.3.net.2.weight\", \"encoder2.layers.1.3.net.2.bias\", \"encoder2.norm.weight\", \"decoder.weight\", \"decoder.bias\". \n\tUnexpected key(s) in state_dict: \"model.projection.weight\", \"model.projection.bias\", \"model.position_embedding.pos_encoding.embedding.weight\", \"model.fund_embedding.weight\", \"model.predict_linear.weight\", \"model.predict_linear.bias\", \"model.encoder.layers.0.0.weight\", \"model.encoder.layers.0.1.att.in_proj_weight\", \"model.encoder.layers.0.1.att.in_proj_bias\", \"model.encoder.layers.0.1.att.out_proj.weight\", \"model.encoder.layers.0.1.att.out_proj.bias\", \"model.encoder.layers.0.2.weight\", \"model.encoder.layers.0.3.net.0.weight\", \"model.encoder.layers.0.3.net.0.bias\", \"model.encoder.layers.0.3.net.2.weight\", \"model.encoder.layers.0.3.net.2.bias\", \"model.encoder.layers.1.0.weight\", \"model.encoder.layers.1.1.att.in_proj_weight\", \"model.encoder.layers.1.1.att.in_proj_bias\", \"model.encoder.layers.1.1.att.out_proj.weight\", \"model.encoder.layers.1.1.att.out_proj.bias\", \"model.encoder.layers.1.2.weight\", \"model.encoder.layers.1.3.net.0.weight\", \"model.encoder.layers.1.3.net.0.bias\", \"model.encoder.layers.1.3.net.2.weight\", \"model.encoder.layers.1.3.net.2.bias\", \"model.encoder.norm.weight\", \"model.encoder2.layers.0.0.weight\", \"model.encoder2.layers.0.1.att.in_proj_weight\", \"model.encoder2.layers.0.1.att.in_proj_bias\", \"model.encoder2.layers.0.1.att.out_proj.weight\", \"model.encoder2.layers.0.1.att.out_proj.bias\", \"model.encoder2.layers.0.2.weight\", \"model.encoder2.layers.0.3.net.0.weight\", \"model.encoder2.layers.0.3.net.0.bias\", \"model.encoder2.layers.0.3.net.2.weight\", \"model.encoder2.layers.0.3.net.2.bias\", \"model.encoder2.layers.1.0.weight\", \"model.encoder2.layers.1.1.att.in_proj_weight\", \"model.encoder2.layers.1.1.att.in_proj_bias\", \"model.encoder2.layers.1.1.att.out_proj.weight\", \"model.encoder2.layers.1.1.att.out_proj.bias\", \"model.encoder2.layers.1.2.weight\", \"model.encoder2.layers.1.3.net.0.weight\", \"model.encoder2.layers.1.3.net.0.bias\", \"model.encoder2.layers.1.3.net.2.weight\", \"model.encoder2.layers.1.3.net.2.bias\", \"model.encoder2.norm.weight\", \"model.decoder.weight\", \"model.decoder.bias\". "
     ]
    }
   ],
   "source": [
    "from modules.backbone import Backbone\n",
    "import torch \n",
    "model = Backbone(3, config).load_state_dict(torch.load('checkpoints/ours/Model_ours_Dataset_financial_Multi_round_0.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9ee673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基金 008783 缺失日期：['2025-04-04']\n",
      "基金 519945 缺失日期：['2025-04-04']\n",
      "基金 007097 缺失日期：['2025-04-04']\n",
      "基金 002994 缺失日期：['2025-04-04']\n",
      "基金 011048 缺失日期：['2025-04-04']\n",
      "基金 001423 缺失日期：['2025-04-04']\n",
      "基金 007561 缺失日期：['2025-04-04']\n",
      "基金 006468 缺失日期：['2025-04-04']\n",
      "基金 519777 缺失日期：['2025-04-04']\n",
      "基金 007116 缺失日期：['2025-04-04']\n",
      "基金 217003 缺失日期：['2025-04-04']\n",
      "基金 002915 缺失日期：['2025-04-04']\n",
      "基金 007954 缺失日期：['2025-04-04']\n",
      "基金 002364 缺失日期：['2025-04-04']\n",
      "基金 008582 缺失日期：['2025-04-04']\n",
      "基金 012750 缺失日期：['2025-04-04']\n",
      "基金 002363 缺失日期：['2025-04-04']\n",
      "基金 002966 缺失日期：['2025-04-04']\n",
      "基金 006077 缺失日期：['2025-04-04']\n",
      "基金 005363 缺失日期：['2025-04-04']\n",
      "基金 011049 缺失日期：['2025-04-04']\n",
      "基金 007259 缺失日期：['2025-04-04']\n",
      "基金 003330 缺失日期：['2025-04-04']\n",
      "基金 006076 缺失日期：['2025-04-04']\n",
      "基金 006897 缺失日期：['2025-04-04']\n",
      "基金 003329 缺失日期：['2025-04-04']\n",
      "基金 003619 缺失日期：['2025-04-04']\n",
      "基金 003041 缺失日期：['2025-04-04']\n",
      "基金 011094 缺失日期：['2025-04-04']\n",
      "基金 012625 缺失日期：['2025-04-04']\n",
      "基金 007768 缺失日期：['2025-04-04']\n",
      "基金 003618 缺失日期：['2025-04-04']\n",
      "基金 005431 缺失日期：['2025-04-04']\n",
      "基金 000199 缺失日期：['2025-04-04']\n",
      "基金 002268 缺失日期：['2025-04-04']\n",
      "基金 008652 缺失日期：['2025-04-04']\n",
      "基金 003209 缺失日期：['2025-04-04']\n",
      "基金 012624 缺失日期：['2025-04-04']\n",
      "基金 005302 缺失日期：['2025-04-04']\n",
      "基金 512390 缺失日期：['2025-04-04']\n",
      "基金 013716 缺失日期：['2025-04-04']\n",
      "基金 006978 缺失日期：['2025-04-04']\n",
      "基金 001422 缺失日期：['2025-04-04']\n",
      "基金 003210 缺失日期：['2025-04-04']\n",
      "基金 007560 缺失日期：['2025-04-04']\n",
      "基金 008653 缺失日期：['2025-04-04']\n",
      "基金 519519 缺失日期：['2025-04-04']\n",
      "基金 008081 缺失日期：['2025-04-04']\n",
      "基金 164703 缺失日期：['2025-04-04']\n",
      "基金 005201 缺失日期：['2025-04-04']\n",
      "基金 005301 缺失日期：['2025-04-04']\n",
      "基金 005362 缺失日期：['2025-04-04']\n",
      "基金 519944 缺失日期：['2025-04-04']\n",
      "基金 004108 缺失日期：['2025-04-04']\n",
      "基金 006210 缺失日期：['2025-04-04']\n",
      "基金 010767 缺失日期：['2025-04-04']\n",
      "基金 007870 缺失日期：['2025-04-04']\n",
      "基金 007098 缺失日期：['2025-04-04']\n",
      "基金 000016 缺失日期：['2025-04-04']\n",
      "基金 003123 缺失日期：['2025-04-04']\n",
      "基金 013717 缺失日期：['2025-04-04']\n",
      "基金 005200 缺失日期：['2025-04-04']\n",
      "基金 006979 缺失日期：['2025-04-04']\n",
      "基金 310508 缺失日期：['2025-04-04']\n",
      "基金 013391 缺失日期：['2025-04-04']\n",
      "基金 004168 缺失日期：['2025-04-04']\n",
      "基金 004059 缺失日期：['2025-04-04']\n",
      "基金 350005 缺失日期：['2025-04-04']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_array_to_df(array):\n",
    "    \"\"\"\n",
    "    将数组转换为包含标准日期列的 DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(array, columns=[\n",
    "        'fund_code', 'year', 'month', 'day', 'weekday',\n",
    "        'value1', 'value2', 'value3'\n",
    "    ])\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    df['month'] = df['month'].astype(int)\n",
    "    df['day'] = df['day'].astype(int)\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    return df\n",
    "\n",
    "def find_missing_dates_from_array_list(array_list, start_date, end_date, freq='B'):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    - array_list: List[np.ndarray]，每个元素是一个基金的历史数据数组\n",
    "    - start_date, end_date: 'YYYY-MM-DD'\n",
    "    - freq: 'B' 表示工作日（默认）\n",
    "\n",
    "    返回：\n",
    "    - dict: {fund_code: [缺失的日期列表]}\n",
    "    \"\"\"\n",
    "    full_range = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "    missing_map = {}\n",
    "\n",
    "    for arr in array_list:\n",
    "        df = convert_array_to_df(arr)\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        fund_code = df.iloc[0]['fund_code']\n",
    "        date_series = df['date']\n",
    "        missing = full_range.difference(date_series)\n",
    "\n",
    "        if not missing.empty:\n",
    "            missing_map[fund_code] = missing.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "    return missing_map\n",
    "\n",
    "missing_map = find_missing_dates_from_array_list(df, start_date, end_date)\n",
    "\n",
    "for code, dates in missing_map.items():\n",
    "    print(f\"基金 {code} 缺失日期：{dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531b688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "df = np.array(all_history_input)\n",
    "df.shape\n",
    "#%%\n",
    "data = np.stack(df, axis=0)\n",
    "data = data.transpose(1, 0, 2)\n",
    "x = data[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df7211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
