{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbb56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c57e88a02587ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:14:22.195421477Z",
     "start_time": "2025-05-14T05:39:11.932833Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_provider.data_loader import DataModule\n",
    "from exp.exp_model import Model\n",
    "from utils.exp_logger import Logger\n",
    "from utils.exp_metrics_plotter import MetricsPlotter\n",
    "from run_train import get_experiment_name\n",
    "from utils.utils import set_settings\n",
    "# Experiment Settings, logger, plotter\n",
    "from utils.exp_config import get_config\n",
    "config = get_config('FinancialConfig')\n",
    "config.multi_dataset = True\n",
    "set_settings(config)\n",
    "log_filename, exper_detail = get_experiment_name(config)\n",
    "plotter = MetricsPlotter(log_filename, config)\n",
    "log = Logger(log_filename, exper_detail, plotter, config)\n",
    "datamodule = DataModule(config)\n",
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e74961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d067d4d4b3419b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:39:54.525191Z",
     "start_time": "2025-05-14T07:39:54.497395Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设输入\n",
    "bs, seq_len, channels, dim = 16, 48, 33, 64\n",
    "x_enc = torch.randn(bs, seq_len, channels, dim)\n",
    "\n",
    "# 定义 attention 层（无 batch_first 参数）\n",
    "attn_channel = nn.MultiheadAttention(embed_dim=dim, num_heads=8)  # expects (seq_len, batch, dim)\n",
    "attn_time = nn.MultiheadAttention(embed_dim=dim, num_heads=8)\n",
    "\n",
    "# ===== 1. 跨通道 attention =====\n",
    "# 原始 x_enc: (bs, 48, 33, 64)\n",
    "# 调整为 (33, bs*48, 64)\n",
    "x_enc_reshaped = x_enc.permute(2, 0, 1, 3).reshape(channels, bs * seq_len, dim)\n",
    "\n",
    "# 注意力：通道之间的 self-attention\n",
    "x_channel_attn, _ = attn_channel(x_enc_reshaped, x_enc_reshaped, x_enc_reshaped)  # (33, bs*48, 64)\n",
    "\n",
    "# 还原为 (bs, 48, 33, 64)\n",
    "x_channel_attn = x_channel_attn.reshape(channels, bs, seq_len, dim).permute(1, 2, 0, 3)\n",
    "\n",
    "# ===== 2. 跨时间 attention =====\n",
    "# 调整为 (48, bs*33, 64)\n",
    "x_time_input = x_channel_attn.permute(1, 0, 2, 3).reshape(seq_len, bs * channels, dim)\n",
    "\n",
    "# 注意力：时间步之间的 self-attention\n",
    "x_time_attn, _ = attn_time(x_time_input, x_time_input, x_time_input)  # (48, bs*33, 64)\n",
    "\n",
    "# 还原为 (bs, 48, 33, 64)\n",
    "x_time_attn = x_time_attn.reshape(seq_len, bs, channels, dim).permute(1, 0, 2, 3)\n",
    "\n",
    "# 最终输出\n",
    "print(x_time_attn.shape)  # torch.Size([16, 48, 33, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b77a8a50c3e4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:54:42.394091Z",
     "start_time": "2025-05-15T08:54:42.206443Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.backbone import Backbone\n",
    "from run_train import *\n",
    "\n",
    "from utils.exp_config import get_config\n",
    "config = get_config()\n",
    "# datamodule = DataModule(config)\n",
    "# model = Model(datamodule, config)\n",
    "model = Backbone(3, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc9844e24299a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:54:44.753971Z",
     "start_time": "2025-05-15T08:54:44.746305Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 33, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df9f4965779f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T08:55:06.532773Z",
     "start_time": "2025-05-15T08:55:06.526640Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 1, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1fd89c0e320dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:27:41.716108Z",
     "start_time": "2025-05-15T07:27:41.708539Z"
    }
   },
   "outputs": [],
   "source": [
    "bs, seq_len, channels, dim = 1, 48, 16, 3\n",
    "random_inputs = torch.rand(bs, seq_len, channels, dim)\n",
    "y = model(random_inputs, None, None)\n",
    "# [1, 48, 32, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d341a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(2*3*4*10).reshape(2, 3, 4, 10)\n",
    "patch_len = 4\n",
    "stride = 2\n",
    "\n",
    "x_unfolded = x.unfold(dimension=-1, size=patch_len, step=stride)\n",
    "print(x_unfolded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 读取所有文件名\n",
    "all_files = os.listdir('results/financial/20250701/log')\n",
    "\n",
    "# 提取每个文件中 _Multi_ 与 .md 之间的数字\n",
    "existing_ids = set()\n",
    "for filename in all_files:\n",
    "    try:\n",
    "        num = int(filename.split('_Multi_')[1].split('.md')[0])\n",
    "        existing_ids.add(num)\n",
    "    except (IndexError, ValueError):\n",
    "        continue\n",
    "\n",
    "# 检查 1-130 中缺失的编号\n",
    "missing_ids = [i for i in range(0, 150) if i not in existing_ids]\n",
    "\n",
    "print(\"缺失的编号：\", missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from collections import Counter\n",
    "data = pickle.load(open('./datasets/func_code_to_label_150.pkl', 'rb'))\n",
    "# 提取组号列\n",
    "group_ids = data[:, 1]\n",
    "\n",
    "# 统计每个组号的基金数量\n",
    "counts = Counter(group_ids)\n",
    "\n",
    "# 打印结果\n",
    "for group_id, count in sorted(counts.items()):\n",
    "    print(f\"组号 {group_id} 中有 {count} 个基金\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa2853e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/financial/S20200713_E20250628'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m all_code = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./datasets/financial/S20200713_E20250628\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m all_code_len = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m all_code:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './datasets/financial/S20200713_E20250628'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "all_code = os.listdir('./datasets/financial/S20200713_E20250628')\n",
    "all_code_len = []\n",
    "for code in all_code:\n",
    "    if code.endswith('.pkl'):\n",
    "        with open(os.path.join('./datasets/financial/S20200713_E20250628', code), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            all_code_len.append(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设你已经有 all_code_len\n",
    "all_code_len = np.array(all_code_len)\n",
    "\n",
    "print(f\"📊 总文件数: {len(all_code_len)}\")\n",
    "print(f\"📈 最大长度: {np.max(all_code_len)}\")\n",
    "print(f\"📉 最小长度: {np.min(all_code_len)}\")\n",
    "print(f\"📏 平均长度: {np.mean(all_code_len):.2f}\")\n",
    "print(f\"📐 中位数: {np.median(all_code_len)}\")\n",
    "print(f\"🔹 5%分位数: {np.percentile(all_code_len, 5)}\")\n",
    "print(f\"🔹 6%分位数: {np.percentile(all_code_len, 6)}\")\n",
    "print(f\"🔹 10%分位数: {np.percentile(all_code_len, 10)}\")\n",
    "print(f\"🔹 25%分位数: {np.percentile(all_code_len, 25)}\")\n",
    "print(f\"🔸 75%分位数: {np.percentile(all_code_len, 75)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc52bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import pickle\n",
    "# 数据库配置\n",
    "with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "    DB_URI = pickle.load(f)\n",
    "engine = create_engine(DB_URI)\n",
    "\n",
    "def query_fund_data(fund, start_date, end_date):\n",
    "    \"\"\"查询数据库中某支基金的净值数据\n",
    "        SELECT fund_code, date, nav, accnav, adj_nav\n",
    "    \"\"\"\n",
    "    sql = text(\"\"\"\n",
    "        SELECT fund_code, date, accnav, adj_nav, nav\n",
    "        FROM b_fund_nav_details_new\n",
    "        WHERE fund_code IN :codes\n",
    "          AND date BETWEEN :start AND :end\n",
    "        ORDER BY date\n",
    "    \"\"\")\n",
    "    try:\n",
    "        df = pd.read_sql_query(\n",
    "            sql.bindparams(codes=tuple(fund), start=start_date, end=end_date),\n",
    "            engine\n",
    "        )\n",
    "        fund_dict = {code: df_group.reset_index(drop=True)\n",
    "                     for code, df_group in df.groupby(\"fund_code\")}\n",
    "        return fund_dict\n",
    "    except Exception as e:\n",
    "        print(f\"[{fund}] 数据库查询失败: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "df = query_fund_data(['000001', '000003'], '2020-01-01', '2025-01-01')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ed66ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "with open('./datasets/func_code_to_label_150.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data = data[:, 0]\n",
    "df = query_fund_data(data, '2020-01-01', '2025-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3a5fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值: 0.0871, 最大值: 141.426\n"
     ]
    }
   ],
   "source": [
    "min_value, max_value = 1e9, -1e9\n",
    "for fund_code, value in df.items():\n",
    "    min_value = min(min_value, value['nav'].min())\n",
    "    max_value = max(max_value, value['nav'].max())\n",
    "print(f\"最小值: {min_value}, 最大值: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fad1c552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'970135'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791128b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def constrain_nav_prediction(predictions, bar=0.05, scale=0.9):\n",
    "    \"\"\"\n",
    "    检测单位净值预测中是否存在超过bar的相邻涨跌幅，\n",
    "    如果是，则整条基金的净值序列按相对首日值重新缩放（温和调整）\n",
    "\n",
    "    参数：\n",
    "    - predictions: np.ndarray [7, 64]，表示64支基金7天的预测单位净值\n",
    "    - bar: float，单位净值日涨跌幅上限（如0.05表示5%）\n",
    "    - scale: float，检测异常后，使用的趋势缩放系数（如0.9）\n",
    "\n",
    "    返回：\n",
    "    - adjusted: np.ndarray [7, 64]，处理后的单位净值预测\n",
    "    - mask: np.ndarray [64]，表示哪些基金被缩放（True为缩放）\n",
    "    \"\"\"\n",
    "    adjusted = predictions.copy()\n",
    "    mask = np.zeros(predictions.shape[1], dtype=bool)\n",
    "    for fund_idx in range(predictions.shape[1]):\n",
    "        nav_series = predictions[:, fund_idx]\n",
    "        # 计算相邻涨跌幅\n",
    "        returns = nav_series[1:] / nav_series[:-1] - 1\n",
    "        if np.any(np.abs(returns) > bar):\n",
    "            # 以首日为锚点，重构温和曲线\n",
    "            # \t•\t以首日值为锚点，计算整个序列相对于首日的累计变化幅度；\n",
    "\t        #   •\t然后将这些累计变化幅度乘以 scale（比如0.9），形成温和版本；\n",
    "\t        #   •\t最后用 base * (1 + 相对变化 * 缩放因子) 得到缩放后的单位净值曲线；\n",
    "\t        #   •\t更新 adjusted 和 mask。\n",
    "            base = nav_series[0]\n",
    "            relative_change = (nav_series - base) / base\n",
    "            softened = base * (1 + relative_change * scale)\n",
    "            adjusted[:, fund_idx] = softened\n",
    "            mask[fund_idx] = True\n",
    "    return adjusted, mask\n",
    "\n",
    "# 模拟单位净值预测（中间人为插入一个异常）\n",
    "np.random.seed(0)\n",
    "preds = np.cumprod(1 + np.random.normal(0, 0.01, (7, 1)), axis=0)\n",
    "preds[:, 0] *= [1, 1, 1.2, 1.5, 1.7, 10.0, 2.5]  # 第6支基金异常暴涨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb60e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01764052,  1.02171269,  1.23805509,  1.58224823,  1.82670398,\n",
       "       10.64030593,  2.68534956])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67393c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被缩放的基金编号：[0]\n"
     ]
    }
   ],
   "source": [
    "adjusted, flagged = constrain_nav_prediction(preds, bar=1, scale=0.5)\n",
    "print(f\"被缩放的基金编号：{np.where(flagged)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cfbdcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01764052, 1.0196766 , 1.12784781, 1.29994438, 1.42217225,\n",
       "       5.82897323, 1.85149504])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d1e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "240 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2066e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "start_date: str = '2020-07-13' \n",
    "end_date: str = '2025-06-28'\n",
    "dir_name = 'S' + (start_date + '_E' + end_date).replace('-', '')\n",
    "all_address = os.listdir(f'./datasets/financial/{dir_name}')\n",
    "all_code_list = [item.split('.')[0] for item in all_address]\n",
    "len(all_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e249865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('./datasets/all_code_list.pkl', 'wb') as f:\n",
    "    pickle.dump(all_code_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5efde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "240 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4211a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fund_code', 'adj_nav', 'bid_close', 'ask_close', 'gdp', 'gdp_yoy',\n",
       "       'pi_yoy', 'si_yoy', 'ti_yoy', '1w', '2w', '1m', '3m', '6m', '9m', '1y',\n",
       "       'cumulative', 'annual_volatility', 'stability', 'monthwin',\n",
       "       'winning_day', 'maxDrawdown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_provider.get_nav_features import get_df_date_as_index\n",
    "\n",
    "df = get_df_date_as_index(\"000010\", \"2025-03-01\", \"2025-4-14\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f2b714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fund_code</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>market</th>\n",
       "      <th>survival_status</th>\n",
       "      <th>tu_fund_type</th>\n",
       "      <th>establish_time</th>\n",
       "      <th>tu_invest_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159901</td>\n",
       "      <td>易方达深证100ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2006-03-24</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159915</td>\n",
       "      <td>易方达创业板ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159925</td>\n",
       "      <td>南方沪深300ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159930</td>\n",
       "      <td>汇添富中证能源ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159931</td>\n",
       "      <td>汇添富中证金融地产ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>588360</td>\n",
       "      <td>科创创业ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>159783</td>\n",
       "      <td>双创基金ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>159781</td>\n",
       "      <td>双创50ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>159780</td>\n",
       "      <td>双创ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>159839</td>\n",
       "      <td>生物药ETF</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>股票型</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>被动指数型</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fund_code     fund_name market survival_status tu_fund_type  \\\n",
       "0      159901   易方达深证100ETF      E               L          股票型   \n",
       "1      159915     易方达创业板ETF      E               L          股票型   \n",
       "2      159925    南方沪深300ETF      E               L          股票型   \n",
       "3      159930    汇添富中证能源ETF      E               L          股票型   \n",
       "4      159931  汇添富中证金融地产ETF      E               L          股票型   \n",
       "..        ...           ...    ...             ...          ...   \n",
       "318    588360       科创创业ETF      E               L          股票型   \n",
       "319    159783       双创基金ETF      E               L          股票型   \n",
       "320    159781       双创50ETF      E               L          股票型   \n",
       "321    159780         双创ETF      E               L          股票型   \n",
       "322    159839        生物药ETF      E               L          股票型   \n",
       "\n",
       "    establish_time tu_invest_type  \n",
       "0       2006-03-24          被动指数型  \n",
       "1       2011-09-20          被动指数型  \n",
       "2       2013-02-18          被动指数型  \n",
       "3       2013-08-23          被动指数型  \n",
       "4       2013-08-23          被动指数型  \n",
       "..             ...            ...  \n",
       "318     2021-06-29          被动指数型  \n",
       "319     2021-06-24          被动指数型  \n",
       "320     2021-06-28          被动指数型  \n",
       "321     2021-06-24          被动指数型  \n",
       "322     2021-02-01          被动指数型  \n",
       "\n",
       "[323 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pickle \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 数据库配置\n",
    "with open('./datasets/sql_token.pkl', 'rb') as f:\n",
    "    DB_URI = pickle.load(f)\n",
    "engine = create_engine(DB_URI)\n",
    "\n",
    "create_date = '2023-7-13'\n",
    "date_list = create_date.split('-')\n",
    "base_date = str(int(date_list[0]) - 1) + '-' + date_list[1] + '-' + date_list[2]  # 筛选成立1年以上的基金\n",
    "first_date = str(int(date_list[0]) - 2) + '-' + date_list[1] + '-' + date_list[2]  # 筛选成立1-2年的基金\n",
    "second_date = str(int(date_list[0]) - 3) + '-' + date_list[1] + '-' + date_list[2]  # 筛选成立2-3年的基金\n",
    "# print(base_date, first_date, second_date)\n",
    "sql = f\"\"\"\n",
    "    SELECT fund_code, fund_name, market, survival_status, tu_fund_type, establish_time, tu_invest_type\n",
    "    FROM b_fund_list\n",
    "    WHERE establish_time < '{base_date}' AND fund_code IN (\n",
    "        SELECT fund_code FROM b_fund_nav\n",
    "            WHERE date = (\n",
    "                SELECT MAX(date) FROM b_fund_nav\n",
    "            )\n",
    "            AND sub_status NOT LIKE '%%暂停申购%%' \n",
    "            AND red_status NOT LIKE '%%封闭期%%'\n",
    "        )\n",
    "    \"\"\"\n",
    "sql = f\"\"\"\n",
    "    SELECT fund_code, fund_name, market, survival_status, tu_fund_type, establish_time, tu_invest_type\n",
    "    FROM b_fund_list\n",
    "    WHERE establish_time < '{base_date}'\n",
    "    AND fund_code IN (\n",
    "        SELECT fund_code FROM b_fund_nav\n",
    "        WHERE date = (SELECT MAX(date) FROM b_fund_nav)\n",
    "        AND sub_status NOT LIKE '%%暂停申购%%'\n",
    "        AND red_status NOT LIKE '%%封闭期%%'\n",
    "    )\n",
    "    \"\"\"\n",
    "df = pd.read_sql_query(sql, engine)\n",
    "print(df.shape)  # 打印df的形状，确认是否有数据\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73263eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 剔除定开、货币型基金\n",
    "df = df[df['survival_status'] != 'D']\n",
    "df = df[~df['fund_name'].str.contains('定开')]\n",
    "df = df[~(df['tu_fund_type'] == '货币市场型')]\n",
    "df = df.drop(['fund_name'], axis=1)\n",
    "df = df.drop(['survival_status'], axis=1)\n",
    "\n",
    "# 按成立时间划分，3类：1-2年，2-3年，3年以上\n",
    "df['establish_time'] = pd.to_datetime(df['establish_time'], format='%Y-%m-%d')\n",
    "df.loc[df['establish_time'] > first_date, 'establish_type'] = 1\n",
    "df.loc[(df['establish_type'] != 1) & (df['establish_time'] > second_date), 'establish_type'] = 2\n",
    "df.loc[(df['establish_type'] != 1) & (df['establish_type'] != 2), 'establish_type'] = 3\n",
    "df = df.drop(['establish_time'], axis=1)\n",
    "\n",
    "# 划分基金类型，五类：stock/bond/index(O or E)/other/mix\n",
    "df.loc[(df['tu_invest_type'] == '被动指数型') & (df['market'] == 'O'), 'tu_fund_type'] = 'index_O'\n",
    "df.loc[(df['tu_invest_type'] == '被动指数型') & (df['market'] == 'E'), 'tu_fund_type'] = 'index_E'\n",
    "df.loc[df['tu_fund_type'] == '股票型', 'tu_fund_type'] = 'stock'\n",
    "df.loc[df['tu_fund_type'] == '债券型', 'tu_fund_type'] = 'bond'\n",
    "df.loc[df['tu_fund_type'] == '混合型', 'tu_fund_type'] = 'mix'\n",
    "df.loc[(df['tu_fund_type'] != 'stock') & (df['tu_fund_type'] != 'bond') &\n",
    "        (df['tu_fund_type'] != 'mix') & (df['tu_fund_type'] != 'index_E') &\n",
    "        (df['tu_fund_type'] != 'index_O'), 'tu_fund_type'] = 'other'\n",
    "\n",
    "df = df.drop(['tu_invest_type'], axis=1)\n",
    "df = df.drop(['market'], axis=1)\n",
    "code_list = df['fund_code']\n",
    "\n",
    "# 2025年07月04日20:10:32，暂时用这里\n",
    "with open('./datasets/all_code_list.pkl', 'rb') as f:\n",
    "    code_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdacd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base date  2022-7-13\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(pymysql.err.ProgrammingError) (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ')' at line 1\")\n[SQL: select fund_code, fund_name, market, survival_status,tu_fund_type,establish_time,tu_invest_type from b_fund_list WHERE establish_time < '2022-7-13')]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1963\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1963\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1964\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/default.py:943\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:563\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m._execute_command(COMMAND.COM_QUERY, sql)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:825\u001b[39m, in \u001b[36mConnection._read_query_result\u001b[39m\u001b[34m(self, unbuffered)\u001b[39m\n\u001b[32m    824\u001b[39m     result = MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[38;5;28mself\u001b[39m._result = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:1199\u001b[39m, in \u001b[36mMySQLResult.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m     first_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_packet.is_ok_packet():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:775\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    774\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mProgrammingError\u001b[39m: (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ')' at line 1\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m sql = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mselect fund_code, fund_name, market, survival_status,tu_fund_type,establish_time,tu_invest_type from b_fund_list WHERE establish_time < \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# print(sql)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.shape)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 剔除定开、货币型基金\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pandas/io/sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pandas/io/sql.py:1848\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1793\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1800\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1801\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1802\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1804\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1846\u001b[39m \n\u001b[32m   1847\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1848\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1849\u001b[39m     columns = result.keys()\n\u001b[32m   1851\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pandas/io/sql.py:1671\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1669\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.execute(sql, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1775\u001b[39m, in \u001b[36mConnection.exec_driver_sql\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1770\u001b[39m execution_options = \u001b[38;5;28mself\u001b[39m._execution_options.merge_with(\n\u001b[32m   1771\u001b[39m     execution_options\n\u001b[32m   1772\u001b[39m )\n\u001b[32m   1774\u001b[39m dialect = \u001b[38;5;28mself\u001b[39m.dialect\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1842\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1840\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1841\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1982\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1979\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1981\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1982\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2351\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2352\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2353\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1963\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1961\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1963\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1964\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1968\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1969\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1970\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1974\u001b[39m         context.executemany,\n\u001b[32m   1975\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/sqlalchemy/engine/default.py:943\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    320\u001b[39m conn = \u001b[38;5;28mself\u001b[39m._get_db()\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:563\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    561\u001b[39m     sql = sql.encode(\u001b[38;5;28mself\u001b[39m.encoding, \u001b[33m\"\u001b[39m\u001b[33msurrogateescape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m._execute_command(COMMAND.COM_QUERY, sql)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:825\u001b[39m, in \u001b[36mConnection._read_query_result\u001b[39m\u001b[34m(self, unbuffered)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    824\u001b[39m     result = MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[38;5;28mself\u001b[39m._result = result\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.server_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:1199\u001b[39m, in \u001b[36mMySQLResult.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m         first_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m first_packet.is_ok_packet():\n\u001b[32m   1202\u001b[39m             \u001b[38;5;28mself\u001b[39m._read_ok_packet(first_packet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/connections.py:775\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.unbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ts/lib/python3.12/site-packages/pymysql/err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mProgrammingError\u001b[39m: (pymysql.err.ProgrammingError) (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ')' at line 1\")\n[SQL: select fund_code, fund_name, market, survival_status,tu_fund_type,establish_time,tu_invest_type from b_fund_list WHERE establish_time < '2022-7-13')]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "date_list = create_date.split('-')\n",
    "base_date = str(int(date_list[0])-1)+'-'+date_list[1]+'-'+date_list[2]  # 筛选成立1年以上的基金\n",
    "first_date = str(int(date_list[0])-2)+'-'+date_list[1]+'-'+date_list[2] # 筛选成立1-2年的基金\n",
    "second_date = str(int(date_list[0])-3)+'-'+date_list[1]+'-'+date_list[2] # 筛选成立2-3年的基金\n",
    "print(\"base date \",base_date)\n",
    "# sql = f\"select fund_code, fund_name, survival_status,tu_fund_type from b_fund_list WHERE establish_time < '{base_date}'\"\n",
    "# 获取以今天为界的成立一年以上的仍在每天更新数据的基金\n",
    "sql = f\"select fund_code, fund_name, market, survival_status,tu_fund_type,establish_time,tu_invest_type from b_fund_list WHERE establish_time < '{base_date}' )\"\n",
    "# print(sql)\n",
    "df = pd.read_sql_query(sql, engine)\n",
    "print(df.shape)\n",
    "# 剔除定开、货币型基金\n",
    "df=df[df['survival_status']!='D']\n",
    "df=df[~df['fund_name'].str.contains('定开')]\n",
    "df=df[~(df['tu_fund_type'] == '货币市场型')]\n",
    "df = df.drop(['fund_name'], axis=1)\n",
    "df = df.drop(['survival_status'], axis=1)\n",
    "\n",
    "# 按成立时间划分，3类：1-2年，2-3年，3年以上\n",
    "df['establish_time'] = pd.to_datetime(df['establish_time'], format='%Y-%m-%d')\n",
    "df.loc[df['establish_time'] > first_date, 'establish_type'] = 1\n",
    "df.loc[(df['establish_type'] != 1) & (df['establish_time'] > second_date), 'establish_type'] = 2\n",
    "df.loc[(df['establish_type'] != 1) & (df['establish_type'] != 2), 'establish_type'] = 3\n",
    "df = df.drop(['establish_time'], axis=1)\n",
    "\n",
    "# 划分基金类型，五类：stock/bond/index(O or E)/other/mix\n",
    "df.loc[(df['tu_invest_type'] == '被动指数型') & (df['market'] == 'O'), 'tu_fund_type'] = 'index_O'\n",
    "df.loc[(df['tu_invest_type'] == '被动指数型') & (df['market'] == 'E'), 'tu_fund_type'] = 'index_E'\n",
    "df.loc[df['tu_fund_type'] == '股票型', 'tu_fund_type'] = 'stock'\n",
    "df.loc[df['tu_fund_type'] == '债券型', 'tu_fund_type'] = 'bond'\n",
    "df.loc[df['tu_fund_type'] == '混合型', 'tu_fund_type'] = 'mix'\n",
    "df.loc[(df['tu_fund_type'] != 'stock') & (df['tu_fund_type'] != 'bond') & (df['tu_fund_type'] != 'mix') & (df['tu_fund_type'] != 'index_E') & (df['tu_fund_type'] != 'index_O'), 'tu_fund_type'] = 'other'\n",
    "df = df.drop(['tu_invest_type'], axis=1)\n",
    "df = df.drop(['market'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9458983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基金历史最大涨跌幅：\n",
      "基金0: max_gain = 1.0263, max_drop = -1.0367\n",
      "基金1: max_gain = 1.4499, max_drop = -0.9004\n",
      "基金2: max_gain = 1.2592, max_drop = -1.4107\n",
      "[基金1] 第4步: 跌幅超限 (Δ=-1.0297 < -0.9004)，原值=0.8225 → 新值=1.2048\n",
      "[基金1] 第6步: 跌幅超限 (Δ=-1.2212 < -0.9004)，原值=0.7385 → 新值=1.5479\n",
      "[基金1] 第7步: 跌幅超限 (Δ=-1.2468 < -0.9004)，原值=0.3011 → 新值=0.7743\n",
      "[基金2] 第7步: 涨幅超限 (Δ=1.3072 > 1.2592)，原值=1.4785 → 新值=1.1815\n",
      "\n",
      "原始预测序列：\n",
      " [[0.2257763  0.0675282  1.42474819]\n",
      " [0.54438272 0.11092259 1.15099358]\n",
      " [0.37569802 0.60063869 0.29169375]\n",
      " [0.60170661 1.85227818 0.01349722]\n",
      " [1.05771093 0.82254491 1.22084365]\n",
      " [0.2088636  1.95967012 1.32818605]\n",
      " [0.19686124 0.73846658 0.17136828]\n",
      " [0.11564828 0.3011037  1.47852199]\n",
      " [0.71984421 0.46063877 1.05712223]]\n",
      "\n",
      "约束后预测序列：\n",
      " [[0.2257763  0.0675282  1.42474819]\n",
      " [0.54438272 0.11092259 1.15099358]\n",
      " [0.37569802 0.60063869 0.29169375]\n",
      " [0.60170661 1.85227818 0.01349722]\n",
      " [1.05771093 1.20479629 1.22084365]\n",
      " [0.2088636  1.95967012 1.32818605]\n",
      " [0.19686124 1.54789121 0.17136828]\n",
      " [0.11564828 0.77433718 1.18148516]\n",
      " [0.71984421 0.46063877 1.05712223]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_delta_with_hist_constraints_np(hist, pred):\n",
    "    \"\"\"\n",
    "    hist: shape [seq_len, n]\n",
    "    pred: shape [T_pred, n]\n",
    "    \"\"\"\n",
    "    pred_clipped = pred.copy().T  # shape: [n, T_pred]\n",
    "    hist = hist.copy().T          # shape: [n, seq_len]\n",
    "    N, T_pred = pred_clipped.shape\n",
    "\n",
    "    # Step 1: 计算历史最大涨跌\n",
    "    hist_diff = hist[:, 1:] - hist[:, :-1]\n",
    "    max_gain = np.max(hist_diff, axis=1)  # [n]\n",
    "    max_drop = np.min(hist_diff, axis=1)  # [n]\n",
    "\n",
    "    print(\"基金历史最大涨跌幅：\")\n",
    "    for i in range(N):\n",
    "        print(f\"基金{i}: max_gain = {max_gain[i]:.4f}, max_drop = {max_drop[i]:.4f}\")\n",
    "\n",
    "    # Step 2: 应用递推约束\n",
    "    for i in range(N):\n",
    "        for t in range(1, T_pred):\n",
    "            prev = pred_clipped[i, t - 1]\n",
    "            curr = pred_clipped[i, t]\n",
    "            delta = curr - prev\n",
    "\n",
    "            if delta > max_gain[i]:\n",
    "                low = prev\n",
    "                high = prev + max_gain[i]\n",
    "                if high < low:\n",
    "                    low, high = high, low\n",
    "                new_val = np.random.uniform(low, high)\n",
    "                print(f\"[基金{i}] 第{t}步: 涨幅超限 (Δ={delta:.4f} > {max_gain[i]:.4f})，原值={curr:.4f} → 新值={new_val:.4f}\")\n",
    "                pred_clipped[i, t] = new_val\n",
    "\n",
    "            elif delta < max_drop[i]:\n",
    "                low = prev + max_drop[i]  # 注意是 prev + max_drop（max_drop 是负数）\n",
    "                high = prev\n",
    "                if high < low:\n",
    "                    low, high = high, low\n",
    "                new_val = np.random.uniform(low, high)\n",
    "                print(f\"[基金{i}] 第{t}步: 跌幅超限 (Δ={delta:.4f} < {max_drop[i]:.4f})，原值={curr:.4f} → 新值={new_val:.4f}\")\n",
    "                pred_clipped[i, t] = new_val\n",
    "\n",
    "    return pred_clipped.T  # shape: [T_pred, n]\n",
    "\n",
    "# 示例数据\n",
    "np.random.seed(42)\n",
    "hist = np.abs(np.random.randn(7, 3))   # shape: [7, 3]\n",
    "pred = np.abs(np.random.randn(9, 3))   # shape: [9, 3]\n",
    "\n",
    "clipped = apply_delta_with_hist_constraints_np(hist, pred)\n",
    "\n",
    "print(\"\\n原始预测序列：\\n\", pred)\n",
    "print(\"\\n约束后预测序列：\\n\", clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5db8a43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.208395957946777"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(1).uniform_(4, 9).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b846fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mysql+pymysql://root:qilai123@123.57.74.222:3306/fund'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('datasets/sql_token.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a75fc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 54,\n",
       " '1': 100,\n",
       " '2': 99,\n",
       " '3': 78,\n",
       " '4': 100,\n",
       " '5': 100,\n",
       " '6': 100,\n",
       " '7': 100,\n",
       " '8': 100,\n",
       " '9': 100,\n",
       " '10': 71,\n",
       " '11': 100,\n",
       " '12': 68,\n",
       " '13': 100,\n",
       " '14': 80,\n",
       " '15': 100,\n",
       " '16': 65,\n",
       " '17': 92,\n",
       " '18': 59,\n",
       " '19': 90,\n",
       " '20': 68,\n",
       " '21': 100,\n",
       " '22': 100,\n",
       " '23': 100,\n",
       " '24': 100,\n",
       " '25': 92,\n",
       " '26': 70,\n",
       " '27': 91,\n",
       " '28': 83,\n",
       " '29': 100,\n",
       " '30': 66,\n",
       " '31': 93,\n",
       " '32': 92,\n",
       " '33': 100,\n",
       " '34': 59,\n",
       " '35': 100,\n",
       " '36': 65,\n",
       " '37': 100,\n",
       " '38': 89,\n",
       " '39': 66,\n",
       " '40': 100,\n",
       " '41': 84,\n",
       " '42': 62,\n",
       " '43': 99,\n",
       " '44': 76,\n",
       " '45': 100,\n",
       " '46': 100,\n",
       " '47': 100,\n",
       " '48': 100,\n",
       " '49': 60,\n",
       " '50': 84,\n",
       " '51': 65,\n",
       " '52': 100,\n",
       " '53': 61,\n",
       " '54': 56,\n",
       " '55': 100,\n",
       " '56': 100,\n",
       " '57': 100,\n",
       " '58': 86,\n",
       " '59': 57,\n",
       " '60': 90,\n",
       " '61': 100,\n",
       " '62': 67,\n",
       " '63': 100,\n",
       " '64': 58,\n",
       " '65': 81,\n",
       " '66': 87,\n",
       " '67': 67,\n",
       " '68': 100,\n",
       " '69': 100,\n",
       " '70': 54,\n",
       " '71': 70,\n",
       " '72': 70,\n",
       " '73': 87,\n",
       " '74': 80,\n",
       " '75': 76,\n",
       " '76': 67,\n",
       " '77': 100,\n",
       " '78': 81,\n",
       " '79': 71,\n",
       " '80': 100,\n",
       " '81': 58,\n",
       " '82': 82,\n",
       " '83': 100,\n",
       " '84': 100,\n",
       " '85': 64,\n",
       " '86': 51,\n",
       " '87': 66,\n",
       " '88': 56,\n",
       " '89': 84,\n",
       " '90': 100,\n",
       " '91': 52,\n",
       " '92': 69,\n",
       " '93': 65,\n",
       " '94': 60,\n",
       " '95': 100,\n",
       " '96': 50,\n",
       " '97': 63,\n",
       " '98': 100,\n",
       " '99': 100,\n",
       " '100': 100,\n",
       " '101': 100,\n",
       " '102': 100,\n",
       " '103': 100,\n",
       " '104': 100,\n",
       " '105': 100,\n",
       " '106': 100,\n",
       " '107': 100,\n",
       " '108': 100,\n",
       " '109': 100,\n",
       " '110': 100,\n",
       " '111': 100,\n",
       " '112': 100,\n",
       " '113': 100,\n",
       " '114': 100,\n",
       " '115': 100,\n",
       " '116': 100,\n",
       " '117': 100,\n",
       " '118': 100,\n",
       " '119': 100,\n",
       " '120': 100,\n",
       " '121': 100,\n",
       " '122': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "with open('datasets/func_code_to_label_160_balanced.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "dic = {}\n",
    "for i in range(len(df)):\n",
    "    if df[i][-1] not in dic:\n",
    "        dic[df[i][-1]] = 1\n",
    "    else:\n",
    "        dic[df[i][-1]] += 1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "from run_service import get_history_data\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "DB_URI = 'mysql+pymysql://root:qilai123@123.57.74.222:3306/fund'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948cff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_history_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(data[i][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      6\u001b[0m         all_func_code\u001b[38;5;241m.\u001b[39mappend(data[i][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m history_input \u001b[38;5;241m=\u001b[39m get_history_data(all_func_code, current_date, config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_history_data' is not defined"
     ]
    }
   ],
   "source": [
    "with open(f'./datasets/func_code_to_label_160_balanced.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "all_func_code = []\n",
    "for i in range(len(data)):\n",
    "    if int(data[i][1]) == 1:\n",
    "        all_func_code.append(data[i][0])\n",
    "        \n",
    "def get_history_data(get_group_idx, current_date, config):\n",
    "    all_history_input = []\n",
    "    start_date = get_start_date(current_date, window_size=2000)\n",
    "    fund_dict = query_fund_data(get_group_idx, start_date, current_date)\n",
    "    min_len = 1e9\n",
    "    for key, value in fund_dict.items():\n",
    "        min_len = min(len(value), min_len)\n",
    "\n",
    "    for key, value in fund_dict.items():\n",
    "        df = process_date_columns(value)\n",
    "        df = df[-min_len:, :]\n",
    "        all_history_input.append(df)\n",
    "    data = all_history_input\n",
    "    return data\n",
    "history_input = get_history_data(all_func_code, current_date, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a8405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769a889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
